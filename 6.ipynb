{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'  # 安装graphviz的路径，用于模型可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers import TimeDistributed, Lambda, Input, SpatialDropout1D\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.utils import plot_model\n",
    "from keras import optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = 'chars' # based on words or chars\n",
    "embed_size = 300 # how big is each word vector\n",
    "max_features = 3048 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 58 # max number of words in a comment to use\n",
    "num_rnn_units = 128\n",
    "num_hidden_units = 200\n",
    "drop_prob = 0.2\n",
    "max_norm = 5.0\n",
    "nb_filter = 64\n",
    "filter_length = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = './train.csv'\n",
    "TEST_PATH = './test.csv'\n",
    "QUESTION_PATH = './question.csv'\n",
    "embed_files = {'words': './word_embed.txt', 'chars': './char_embed.txt'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get question id from a list. Remove the Q\n",
    "def get_ids(qids):\n",
    "    ids = []\n",
    "    for t_ in qids:\n",
    "        ids.append(int(t_[1:]))\n",
    "    return np.asarray(ids)\n",
    "\n",
    "# Get the text\n",
    "def get_texts(q_list, question_path=QUESTION_PATH):\n",
    "    qes = pd.read_csv(question_path)\n",
    "    ids = get_ids(q_list)\n",
    "    all_tokens = qes[token]\n",
    "    texts = [all_tokens[t] for t in ids]\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train data\n",
    "split some data for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SJ\\AppData\\Local\\conda\\conda\\envs\\deep\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(TRAIN_PATH)\n",
    "list_train = list(zip(train['q1'], train['q2']))\n",
    "label_train = train['label']\n",
    "#print(len(list_train), len(label_train))\n",
    "\n",
    "X_tra, X_val, y_tra, y_val = train_test_split(list_train, label_train, train_size=0.85, random_state=8, shuffle=True)\n",
    "\n",
    "# get the text list of question 1 and 2\n",
    "q1_train = [i[0] for i in X_tra]\n",
    "text1_train = get_texts(q1_train)\n",
    "q2_train = [i[1] for i in X_tra]\n",
    "text2_train = get_texts(q2_train)\n",
    "q1_val = [i[0] for i in X_val]\n",
    "text1_val = get_texts(q1_val)\n",
    "q2_val = [i[1] for i in X_val]\n",
    "text2_val = get_texts(q2_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(TEST_PATH)\n",
    "list_test = list(zip(test['q1'], test['q2']))\n",
    "\n",
    "# get the text list of question 1 and 2\n",
    "q1_test = [i[0] for i in list_test]\n",
    "text1_test = get_texts(q1_test)\n",
    "q2_test = [i[1] for i in list_test]\n",
    "text2_test = get_texts(q2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_features, lower=False) # Don't lower the W or L!!!\n",
    "tokenizer.fit_on_texts(pd.read_csv(QUESTION_PATH)[token])\n",
    "\n",
    "# train set\n",
    "tokenized1_train = tokenizer.texts_to_sequences(text1_train)\n",
    "tokenized2_train = tokenizer.texts_to_sequences(text2_train)\n",
    "X1_train = pad_sequences(tokenized1_train, maxlen=maxlen)\n",
    "X2_train = pad_sequences(tokenized2_train, maxlen=maxlen)\n",
    "\n",
    "# validation set\n",
    "tokenized1_val = tokenizer.texts_to_sequences(text1_val)\n",
    "tokenized2_val = tokenizer.texts_to_sequences(text2_val)\n",
    "X1_val = pad_sequences(tokenized1_val, maxlen=maxlen)\n",
    "X2_val = pad_sequences(tokenized2_val, maxlen=maxlen)\n",
    "\n",
    "# test set\n",
    "tokenized1_test = tokenizer.texts_to_sequences(text1_test)\n",
    "tokenized2_test = tokenizer.texts_to_sequences(text2_test)\n",
    "X1_test = pad_sequences(tokenized1_test, maxlen=maxlen)\n",
    "X2_test = pad_sequences(tokenized2_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the pretrained word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3048\n"
     ]
    }
   ],
   "source": [
    "def get_coefs(line): return line[0], np.asarray(line[1:], dtype='float32')\n",
    "embed_file = embed_files[token]\n",
    "embeddings_index = dict(get_coefs(o.strip().split()) for o in open(embed_file, encoding='utf-8'))\n",
    "print (len(embeddings_index.items()))\n",
    "#print (list(embeddings_index.items())[20890])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.003230264, 2.2532277)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_embs = np.hstack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "emb_mean,emb_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (max_features+1, embed_size))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i > max_features: break\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    #print (i, word, len(embedding_vector))\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.asarray(embedding_matrix, dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 58)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 58)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 200)          974900      input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 200)          1045108     input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 128)          1134348     input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1056)         0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "                                                                 sequential_2[1][0]               \n",
      "                                                                 sequential_2[2][0]               \n",
      "                                                                 sequential_3[1][0]               \n",
      "                                                                 sequential_3[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 1056)         4224        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 200)          211400      batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_1 (PReLU)               (None, 200)          200         dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 200)          0           p_re_lu_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 200)          800         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 200)          40200       batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_2 (PReLU)               (None, 200)          200         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 200)          0           p_re_lu_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 200)          800         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 200)          40200       batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_3 (PReLU)               (None, 200)          200         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 200)          0           p_re_lu_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 200)          800         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 200)          40200       batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_4 (PReLU)               (None, 200)          200         dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 200)          0           p_re_lu_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 200)          800         dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 200)          40200       batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_5 (PReLU)               (None, 200)          200         dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 200)          0           p_re_lu_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 200)          800         dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            201         batch_normalization_7[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 3,535,981\n",
      "Trainable params: 787,369\n",
      "Non-trainable params: 2,748,612\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp1 = Input(shape=(maxlen,))\n",
    "inp2 = Input(shape=(maxlen,))\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(max_features + 1,\n",
    "                     embed_size,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=maxlen,\n",
    "                     trainable=False))\n",
    "\n",
    "model1.add(TimeDistributed(Dense(num_hidden_units, activation='relu')))\n",
    "model1.add(Lambda(lambda x: K.sum(x, axis=1), output_shape=(num_hidden_units,)))\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Embedding(max_features + 1,\n",
    "                     embed_size,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=maxlen,\n",
    "                     trainable=False))\n",
    "model2.add(Conv1D(filters=nb_filter, kernel_size=filter_length, padding='valid', activation='relu', strides=1))\n",
    "model2.add(Dropout(drop_prob))\n",
    "\n",
    "model2.add(Conv1D(filters=nb_filter, kernel_size=filter_length, padding='valid', activation='relu', strides=1))\n",
    "\n",
    "model2.add(GlobalMaxPooling1D())\n",
    "model2.add(Dropout(drop_prob))\n",
    "\n",
    "model2.add(Dense(num_hidden_units))\n",
    "model2.add(Dropout(drop_prob))\n",
    "model2.add(BatchNormalization())\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Embedding(max_features + 1,\n",
    "                     embed_size,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=maxlen,\n",
    "                     trainable=False))\n",
    "model3.add(SpatialDropout1D(drop_prob))\n",
    "model3.add(LSTM(num_rnn_units, dropout=drop_prob, recurrent_dropout=drop_prob))\n",
    "\n",
    "o1 = model1(inp1)\n",
    "o2 = model1(inp2)\n",
    "o3 = model2(inp1)\n",
    "o4 = model2(inp2)\n",
    "o5 = model3(inp1)\n",
    "o6 = model3(inp2)\n",
    "\n",
    "conc = concatenate([o1,o2,o3,o4,o5,o6])\n",
    "x = BatchNormalization()(conc)\n",
    "\n",
    "x = Dense(num_hidden_units)(x)\n",
    "x = PReLU()(x)\n",
    "x = Dropout(drop_prob)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Dense(num_hidden_units)(x)\n",
    "x = PReLU()(x)\n",
    "x = Dropout(drop_prob)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Dense(num_hidden_units)(x)\n",
    "x = PReLU()(x)\n",
    "x = Dropout(drop_prob)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Dense(num_hidden_units)(x)\n",
    "x = PReLU()(x)\n",
    "x = Dropout(drop_prob)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Dense(num_hidden_units)(x)\n",
    "x = PReLU()(x)\n",
    "x = Dropout(drop_prob)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs=[inp1, inp2], outputs=x)\n",
    "\n",
    "adam = optimizers.Adam(clipnorm=max_norm)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "plot_model(model, to_file='model6.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 216228 samples, validate on 38158 samples\n",
      "Epoch 1/15\n",
      "216228/216228 [==============================] - 134s 620us/step - loss: 0.5248 - acc: 0.7432 - val_loss: 0.4885 - val_acc: 0.7577\n",
      "Epoch 2/15\n",
      "216228/216228 [==============================] - 126s 581us/step - loss: 0.4084 - acc: 0.8101 - val_loss: 0.3657 - val_acc: 0.8353\n",
      "Epoch 3/15\n",
      "216228/216228 [==============================] - 125s 580us/step - loss: 0.3507 - acc: 0.8422 - val_loss: 0.3264 - val_acc: 0.8542\n",
      "Epoch 4/15\n",
      "216228/216228 [==============================] - 128s 591us/step - loss: 0.3150 - acc: 0.8611 - val_loss: 0.3075 - val_acc: 0.8635\n",
      "Epoch 5/15\n",
      "216228/216228 [==============================] - 125s 579us/step - loss: 0.2905 - acc: 0.8731 - val_loss: 0.2809 - val_acc: 0.8791\n",
      "Epoch 6/15\n",
      "216228/216228 [==============================] - 124s 572us/step - loss: 0.2724 - acc: 0.8817 - val_loss: 0.2733 - val_acc: 0.8829\n",
      "Epoch 7/15\n",
      "216228/216228 [==============================] - 125s 580us/step - loss: 0.2580 - acc: 0.8889 - val_loss: 0.2648 - val_acc: 0.8861\n",
      "Epoch 8/15\n",
      "216228/216228 [==============================] - 126s 581us/step - loss: 0.2458 - acc: 0.8936 - val_loss: 0.2669 - val_acc: 0.8835\n",
      "Epoch 9/15\n",
      "216228/216228 [==============================] - 128s 593us/step - loss: 0.2191 - acc: 0.9068 - val_loss: 0.2437 - val_acc: 0.8961\n",
      "Epoch 10/15\n",
      "216228/216228 [==============================] - 136s 627us/step - loss: 0.2089 - acc: 0.9115 - val_loss: 0.2416 - val_acc: 0.8976\n",
      "Epoch 11/15\n",
      "216228/216228 [==============================] - 129s 598us/step - loss: 0.2037 - acc: 0.9139 - val_loss: 0.2420 - val_acc: 0.8974\n",
      "Epoch 12/15\n",
      "216228/216228 [==============================] - 128s 592us/step - loss: 0.1975 - acc: 0.9165 - val_loss: 0.2414 - val_acc: 0.8988\n",
      "Epoch 13/15\n",
      "216228/216228 [==============================] - 127s 585us/step - loss: 0.1971 - acc: 0.9169 - val_loss: 0.2411 - val_acc: 0.8989\n",
      "Epoch 14/15\n",
      "216228/216228 [==============================] - 126s 580us/step - loss: 0.1966 - acc: 0.9169 - val_loss: 0.2410 - val_acc: 0.8991\n",
      "Epoch 15/15\n",
      "216228/216228 [==============================] - 126s 581us/step - loss: 0.1966 - acc: 0.9170 - val_loss: 0.2409 - val_acc: 0.8990\n"
     ]
    }
   ],
   "source": [
    "cp = ModelCheckpoint(filepath=\"my_model6.h5\", save_best_only=True)\n",
    "es = EarlyStopping(patience=2)\n",
    "rp = ReduceLROnPlateau(patience = 0)\n",
    "hist = model.fit([X1_train, X2_train], y_tra, batch_size = 256, epochs=15, validation_data=([X1_val, X2_val], y_val), callbacks=[cp, es, rp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check the loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': [0.48851576960307386, 0.3657366542394659, 0.3264266552837135, 0.307464684562942, 0.2809022940397325, 0.27325343001319324, 0.26479518218287645, 0.2669183613806752, 0.24368520063001584, 0.24163184154582878, 0.24201103084410652, 0.24135006664059086, 0.24108145391174418, 0.24104838246875318, 0.2409479290104817], 'val_acc': [0.757717909737449, 0.8353163163656583, 0.854211436664354, 0.8635410660873626, 0.8790817128842816, 0.8828554955647985, 0.8860527281241569, 0.8834582525352067, 0.8961161486513554, 0.8975837308097494, 0.8974002830399501, 0.8987630379013161, 0.8988940720226013, 0.8990775197924005, 0.8990251061438864], 'loss': [0.52478540705389, 0.40839842460688586, 0.3506582125759236, 0.3149567098993946, 0.2904782699328393, 0.2724396228996474, 0.2580150300542992, 0.2457891197131111, 0.2191196137127739, 0.20885918717062638, 0.20371951200607594, 0.19753543208608978, 0.19711278353547945, 0.19656022558707226, 0.19661278570396518], 'acc': [0.7432154947389964, 0.8100847253615168, 0.8422405979028519, 0.8610725715338245, 0.8731015409770436, 0.8817128216578357, 0.8888950552272089, 0.8936400465976121, 0.9067743307791242, 0.9115424459488254, 0.9139056921243416, 0.9164539282818597, 0.9169302772800398, 0.9168840298005275, 0.9169672752680603], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.000100000005, 0.000100000005, 0.000100000005, 1.0000001e-05, 1.0000001e-05, 1.0000001e-05, 1.0000001e-06]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12801d414a8>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x126478c1860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print (hist.history)\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(1)\n",
    "plt.plot (hist.history['loss'])\n",
    "plt.plot (hist.history['val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('my_model6.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict([X1_test, X2_test], batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make a submission file \n",
    "def make_submission(predict_prob):\n",
    "    with open('sub6.csv', 'w') as file:\n",
    "        file.write(str('y_pre') + '\\n')\n",
    "        for line in predict_prob:\n",
    "            #line = np.clip(line, 0.005, 0.995)\n",
    "            file.write(str(line[0]) + '\\n')\n",
    "    file.close()\n",
    "    \n",
    "make_submission(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
