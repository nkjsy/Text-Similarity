{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'  # 安装graphviz的路径，用于模型可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Activation, Dropout, Reshape, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import concatenate, Concatenate\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.utils import plot_model\n",
    "from keras import optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = 'words' # based on words or chars\n",
    "embed_size = 300 # how big is each word vector\n",
    "max_features = 20890 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 40 # max number of words in a comment to use\n",
    "num_hidden_units = 200\n",
    "drop_prob = 0.2\n",
    "max_norm = 5.0\n",
    "filter_sizes = [1,2,3,5]\n",
    "num_filters = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = './train.csv'\n",
    "TEST_PATH = './test.csv'\n",
    "QUESTION_PATH = './question.csv'\n",
    "embed_files = {'words': './word_embed.txt', 'chars': './char_embed.txt'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get question id from a list. Remove the Q\n",
    "def get_ids(qids):\n",
    "    ids = []\n",
    "    for t_ in qids:\n",
    "        ids.append(int(t_[1:]))\n",
    "    return np.asarray(ids)\n",
    "\n",
    "# Get the text\n",
    "def get_texts(q_list, question_path=QUESTION_PATH):\n",
    "    qes = pd.read_csv(question_path)\n",
    "    ids = get_ids(q_list)\n",
    "    all_tokens = qes[token]\n",
    "    texts = [all_tokens[t] for t in ids]\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train data\n",
    "split some data for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SJ\\AppData\\Local\\conda\\conda\\envs\\deep\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(TRAIN_PATH)\n",
    "list_train = list(zip(train['q1'], train['q2']))\n",
    "label_train = train['label']\n",
    "#print(len(list_train), len(label_train))\n",
    "\n",
    "X_tra, X_val, y_tra, y_val = train_test_split(list_train, label_train, train_size=0.85, random_state=8, shuffle=True)\n",
    "\n",
    "# get the text list of question 1 and 2\n",
    "q1_train = [i[0] for i in X_tra]\n",
    "text1_train = get_texts(q1_train)\n",
    "q2_train = [i[1] for i in X_tra]\n",
    "text2_train = get_texts(q2_train)\n",
    "q1_val = [i[0] for i in X_val]\n",
    "text1_val = get_texts(q1_val)\n",
    "q2_val = [i[1] for i in X_val]\n",
    "text2_val = get_texts(q2_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(TEST_PATH)\n",
    "list_test = list(zip(test['q1'], test['q2']))\n",
    "\n",
    "# get the text list of question 1 and 2\n",
    "q1_test = [i[0] for i in list_test]\n",
    "text1_test = get_texts(q1_test)\n",
    "q2_test = [i[1] for i in list_test]\n",
    "text2_test = get_texts(q2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_features, lower=False) # Don't lower the W or L!!!\n",
    "tokenizer.fit_on_texts(pd.read_csv(QUESTION_PATH)[token])\n",
    "\n",
    "# train set\n",
    "tokenized1_train = tokenizer.texts_to_sequences(text1_train)\n",
    "tokenized2_train = tokenizer.texts_to_sequences(text2_train)\n",
    "X1_train = pad_sequences(tokenized1_train, maxlen=maxlen)\n",
    "X2_train = pad_sequences(tokenized2_train, maxlen=maxlen)\n",
    "\n",
    "# validation set\n",
    "tokenized1_val = tokenizer.texts_to_sequences(text1_val)\n",
    "tokenized2_val = tokenizer.texts_to_sequences(text2_val)\n",
    "X1_val = pad_sequences(tokenized1_val, maxlen=maxlen)\n",
    "X2_val = pad_sequences(tokenized2_val, maxlen=maxlen)\n",
    "\n",
    "# test set\n",
    "tokenized1_test = tokenizer.texts_to_sequences(text1_test)\n",
    "tokenized2_test = tokenizer.texts_to_sequences(text2_test)\n",
    "X1_test = pad_sequences(tokenized1_test, maxlen=maxlen)\n",
    "X2_test = pad_sequences(tokenized2_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the pretrained word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20891\n"
     ]
    }
   ],
   "source": [
    "def get_coefs(line): return line[0], np.asarray(line[1:], dtype='float32')\n",
    "embed_file = embed_files[token]\n",
    "embeddings_index = dict(get_coefs(o.strip().split()) for o in open(embed_file, encoding='utf-8'))\n",
    "print (len(embeddings_index.items()))\n",
    "#print (list(embeddings_index.items())[20890])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.015683081, 1.1956546)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_embs = np.hstack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "emb_mean,emb_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (max_features+1, embed_size))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i > max_features: break\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    #print (i, word, len(embedding_vector))\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.asarray(embedding_matrix, dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 512)          6690212     input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1024)         0           model_1[1][0]                    \n",
      "                                                                 model_1[2][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 1024)         4096        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 200)          205000      batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 200)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 200)          800         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 200)          40200       batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 200)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 200)          800         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 200)          40200       batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 200)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 200)          800         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 200)          40200       batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 200)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 200)          800         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 200)          40200       batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 200)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 200)          800         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            201         batch_normalization_6[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 7,064,309\n",
      "Trainable params: 792,961\n",
      "Non-trainable params: 6,271,348\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp1 = Input(shape=(maxlen,))\n",
    "inp2 = Input(shape=(maxlen,))\n",
    "\n",
    "# basic cnn model\n",
    "inp = Input(shape=(maxlen,))\n",
    "h = Embedding(max_features+1, embed_size, weights=[embedding_matrix], trainable=False)(inp)\n",
    "h = Reshape((maxlen, embed_size, 1))(h)\n",
    "\n",
    "conv_0 = Conv2D(num_filters, kernel_size=(filter_sizes[0], embed_size), activation = 'relu')(h)\n",
    "conv_1 = Conv2D(num_filters, kernel_size=(filter_sizes[1], embed_size), activation = 'relu')(h)\n",
    "conv_2 = Conv2D(num_filters, kernel_size=(filter_sizes[2], embed_size), activation = 'relu')(h)\n",
    "conv_3 = Conv2D(num_filters, kernel_size=(filter_sizes[3], embed_size), activation = 'relu')(h)\n",
    "\n",
    "maxpool_0 = MaxPooling2D(pool_size=(maxlen - filter_sizes[0] + 1, 1))(conv_0)\n",
    "maxpool_1 = MaxPooling2D(pool_size=(maxlen - filter_sizes[1] + 1, 1))(conv_1)\n",
    "maxpool_2 = MaxPooling2D(pool_size=(maxlen - filter_sizes[2] + 1, 1))(conv_2)\n",
    "maxpool_3 = MaxPooling2D(pool_size=(maxlen - filter_sizes[3] + 1, 1))(conv_3)\n",
    "z = Concatenate(axis=1)([maxpool_0, maxpool_1, maxpool_2, maxpool_3])   \n",
    "z = Flatten()(z)\n",
    "\n",
    "base_model = Model(inputs=inp, outputs=z)\n",
    "\n",
    "o1 = base_model(inp1)\n",
    "o2 = base_model(inp2)\n",
    "\n",
    "conc = concatenate([o1,o2])\n",
    "x = BatchNormalization()(conc)\n",
    "\n",
    "x = Dense(num_hidden_units, activation='relu')(x)\n",
    "x = Dropout(drop_prob)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Dense(num_hidden_units, activation='relu')(x)\n",
    "x = Dropout(drop_prob)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Dense(num_hidden_units, activation='relu')(x)\n",
    "x = Dropout(drop_prob)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Dense(num_hidden_units, activation='relu')(x)\n",
    "x = Dropout(drop_prob)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Dense(num_hidden_units, activation='relu')(x)\n",
    "x = Dropout(drop_prob)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs=[inp1, inp2], outputs=x)\n",
    "\n",
    "adam = optimizers.Adam(clipnorm=max_norm)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "plot_model(model, to_file='model5.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 216228 samples, validate on 38158 samples\n",
      "Epoch 1/20\n",
      "216228/216228 [==============================] - 33s 154us/step - loss: 0.4461 - acc: 0.7901 - val_loss: 0.3320 - val_acc: 0.8518\n",
      "Epoch 2/20\n",
      "216228/216228 [==============================] - 30s 138us/step - loss: 0.3164 - acc: 0.8607 - val_loss: 0.2925 - val_acc: 0.8751\n",
      "Epoch 3/20\n",
      "216228/216228 [==============================] - 30s 139us/step - loss: 0.2666 - acc: 0.8850 - val_loss: 0.2598 - val_acc: 0.8877\n",
      "Epoch 4/20\n",
      "216228/216228 [==============================] - 30s 139us/step - loss: 0.2355 - acc: 0.8998 - val_loss: 0.2477 - val_acc: 0.8933\n",
      "Epoch 5/20\n",
      "216228/216228 [==============================] - 30s 139us/step - loss: 0.2098 - acc: 0.9117 - val_loss: 0.2539 - val_acc: 0.8953\n",
      "Epoch 6/20\n",
      "216228/216228 [==============================] - 30s 139us/step - loss: 0.1489 - acc: 0.9406 - val_loss: 0.2345 - val_acc: 0.9061\n",
      "Epoch 7/20\n",
      "216228/216228 [==============================] - 30s 139us/step - loss: 0.1249 - acc: 0.9508 - val_loss: 0.2444 - val_acc: 0.9060\n",
      "Epoch 8/20\n",
      "216228/216228 [==============================] - 30s 139us/step - loss: 0.1065 - acc: 0.9587 - val_loss: 0.2561 - val_acc: 0.9060\n"
     ]
    }
   ],
   "source": [
    "cp = ModelCheckpoint(filepath=\"my_model5.h5\", save_best_only=True)\n",
    "es = EarlyStopping(patience=2)\n",
    "rp = ReduceLROnPlateau(patience = 0)\n",
    "hist = model.fit([X1_train, X2_train], y_tra, batch_size = 256, epochs=20, validation_data=([X1_val, X2_val], y_val), callbacks=[cp, es, rp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check the loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': [0.33203013120310393, 0.29247725593811924, 0.25984684608974723, 0.24774799354296698, 0.2538923866637967, 0.2345227792744267, 0.2444388761142495, 0.2560700664005912], 'val_acc': [0.8517742020084496, 0.8751244824214691, 0.8876775512280932, 0.893285811619099, 0.8953037370993873, 0.9061271555175433, 0.9060223282205152, 0.9060485350447722], 'loss': [0.4460523886007957, 0.3164139621923592, 0.26659184717224776, 0.2354838764523949, 0.20977092116174165, 0.14892336979213724, 0.1248843511190421, 0.1065421387293271], 'acc': [0.7901381874665777, 0.8607072164412664, 0.8849778936937668, 0.899832584104318, 0.9117413101019075, 0.9406459848015472, 0.9508343045480451, 0.9586547533335863], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.000100000005, 0.000100000005, 1.0000001e-05]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2157916d4a8>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21384153128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print (hist.history)\n",
    "%matplotlib inline\n",
    "plt.figure(1)\n",
    "plt.plot (hist.history['loss'])\n",
    "plt.plot (hist.history['val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('my_model5.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict([X1_test, X2_test], batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make a submission file \n",
    "def make_submission(predict_prob):\n",
    "    with open('sub5.csv', 'w') as file:\n",
    "        file.write(str('y_pre') + '\\n')\n",
    "        for line in predict_prob:\n",
    "            #line = np.clip(line, 0.005, 0.995)\n",
    "            file.write(str(line[0]) + '\\n')\n",
    "    file.close()\n",
    "    \n",
    "make_submission(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
