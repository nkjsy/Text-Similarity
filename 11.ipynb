{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'  # 安装graphviz的路径，用于模型可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Activation, Dropout, Reshape, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import concatenate, Concatenate\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, GlobalAveragePooling1D, Input, SpatialDropout1D, Bidirectional\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.utils import plot_model\n",
    "from keras import optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = 'words' # based on words or chars\n",
    "embed_size = 300 # how big is each word vector\n",
    "max_features = 20890 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 15 # max number of words in a comment to use\n",
    "num_rnn_units = 128\n",
    "num_hidden_units = 300\n",
    "drop_prob = 0.2\n",
    "max_norm = 5.0\n",
    "filter_sizes = [1,2,3,5]\n",
    "num_filters = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = './train.csv'\n",
    "TEST_PATH = './test.csv'\n",
    "QUESTION_PATH = './question.csv'\n",
    "embed_files = {'words': './word_embed.txt', 'chars': './char_embed.txt'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get question id from a list. Remove the Q\n",
    "def get_ids(qids):\n",
    "    ids = []\n",
    "    for t_ in qids:\n",
    "        ids.append(int(t_[1:]))\n",
    "    return np.asarray(ids)\n",
    "\n",
    "# Get the text\n",
    "def get_texts(q_list, question_path=QUESTION_PATH):\n",
    "    qes = pd.read_csv(question_path)\n",
    "    ids = get_ids(q_list)\n",
    "    all_tokens = qes[token]\n",
    "    texts = [all_tokens[t] for t in ids]\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train data\n",
    "split some data for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SJ\\AppData\\Local\\conda\\conda\\envs\\deep\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(TRAIN_PATH)\n",
    "list_train = list(zip(train['q1'], train['q2']))\n",
    "label_train = train['label']\n",
    "#print(len(list_train), len(label_train))\n",
    "\n",
    "X_tra, X_val, y_tra, y_val = train_test_split(list_train, label_train, train_size=0.85, random_state=11, shuffle=True)\n",
    "\n",
    "# get the text list of question 1 and 2\n",
    "q1_train = [i[0] for i in X_tra]\n",
    "text1_train = get_texts(q1_train)\n",
    "q2_train = [i[1] for i in X_tra]\n",
    "text2_train = get_texts(q2_train)\n",
    "q1_val = [i[0] for i in X_val]\n",
    "text1_val = get_texts(q1_val)\n",
    "q2_val = [i[1] for i in X_val]\n",
    "text2_val = get_texts(q2_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(TEST_PATH)\n",
    "list_test = list(zip(test['q1'], test['q2']))\n",
    "\n",
    "# get the text list of question 1 and 2\n",
    "q1_test = [i[0] for i in list_test]\n",
    "text1_test = get_texts(q1_test)\n",
    "q2_test = [i[1] for i in list_test]\n",
    "text2_test = get_texts(q2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_features, lower=False) # Don't lower the W or L!!!\n",
    "tokenizer.fit_on_texts(pd.read_csv(QUESTION_PATH)[token])\n",
    "\n",
    "# train set\n",
    "tokenized1_train = tokenizer.texts_to_sequences(text1_train)\n",
    "tokenized2_train = tokenizer.texts_to_sequences(text2_train)\n",
    "X1_train = pad_sequences(tokenized1_train, maxlen=maxlen)\n",
    "X2_train = pad_sequences(tokenized2_train, maxlen=maxlen)\n",
    "\n",
    "# validation set\n",
    "tokenized1_val = tokenizer.texts_to_sequences(text1_val)\n",
    "tokenized2_val = tokenizer.texts_to_sequences(text2_val)\n",
    "X1_val = pad_sequences(tokenized1_val, maxlen=maxlen)\n",
    "X2_val = pad_sequences(tokenized2_val, maxlen=maxlen)\n",
    "\n",
    "# test set\n",
    "tokenized1_test = tokenizer.texts_to_sequences(text1_test)\n",
    "tokenized2_test = tokenizer.texts_to_sequences(text2_test)\n",
    "X1_test = pad_sequences(tokenized1_test, maxlen=maxlen)\n",
    "X2_test = pad_sequences(tokenized2_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the pretrained word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20891\n"
     ]
    }
   ],
   "source": [
    "def get_coefs(line): return line[0], np.asarray(line[1:], dtype='float32')\n",
    "embed_file = embed_files[token]\n",
    "embeddings_index = dict(get_coefs(o.strip().split()) for o in open(embed_file, encoding='utf-8'))\n",
    "print (len(embeddings_index.items()))\n",
    "#print (list(embeddings_index.items())[20890])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.015683081, 1.1956546)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_embs = np.hstack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "emb_mean,emb_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (max_features+1, embed_size))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i > max_features: break\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    #print (i, word, len(embedding_vector))\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.asarray(embedding_matrix, dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 15)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 15)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 1024)         7067556     input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 2048)         0           model_1[1][0]                    \n",
      "                                                                 model_1[2][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 2048)         8192        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 300)          614700      batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 300)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 300)          1200        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            301         batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 7,691,949\n",
      "Trainable params: 7,687,253\n",
      "Non-trainable params: 4,696\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp1 = Input(shape=(maxlen,))\n",
    "inp2 = Input(shape=(maxlen,))\n",
    "\n",
    "# basic cnn+rnn model\n",
    "inp = Input(shape=(maxlen,))\n",
    "h = Embedding(max_features+1, embed_size, weights=[embedding_matrix], trainable=True)(inp)\n",
    "h = SpatialDropout1D(drop_prob)(h)\n",
    "h = Bidirectional(LSTM(num_rnn_units, return_sequences=True, dropout=drop_prob, recurrent_dropout=drop_prob))(h)\n",
    "    \n",
    "conv_0 = Conv1D(num_filters, kernel_size=filter_sizes[0], padding = \"valid\", activation = 'relu')(h)\n",
    "conv_1 = Conv1D(num_filters, kernel_size=filter_sizes[1], padding = \"valid\", activation = 'relu')(h)\n",
    "conv_2 = Conv1D(num_filters, kernel_size=filter_sizes[2], padding = \"valid\", activation = 'relu')(h)\n",
    "conv_3 = Conv1D(num_filters, kernel_size=filter_sizes[3], padding = \"valid\", activation = 'relu')(h)\n",
    "maxpool_0 = GlobalMaxPooling1D()(conv_0)\n",
    "avgpool_0 = GlobalAveragePooling1D()(conv_0)\n",
    "maxpool_1 = GlobalMaxPooling1D()(conv_1)\n",
    "avgpool_1 = GlobalAveragePooling1D()(conv_1)\n",
    "maxpool_2 = GlobalMaxPooling1D()(conv_2)\n",
    "avgpool_2 = GlobalAveragePooling1D()(conv_2)\n",
    "maxpool_3 = GlobalMaxPooling1D()(conv_3)\n",
    "avgpool_3 = GlobalAveragePooling1D()(conv_3)\n",
    "\n",
    "z = concatenate([maxpool_0, maxpool_1, maxpool_2, maxpool_3, avgpool_0, avgpool_1, avgpool_2, avgpool_3])\n",
    "\n",
    "base_model = Model(inputs=inp, outputs=z)\n",
    "\n",
    "o1 = base_model(inp1)\n",
    "o2 = base_model(inp2)\n",
    "\n",
    "conc = concatenate([o1,o2])\n",
    "x = BatchNormalization()(conc)\n",
    "\n",
    "x = Dense(num_hidden_units, activation='relu')(x)\n",
    "x = Dropout(drop_prob)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs=[inp1, inp2], outputs=x)\n",
    "\n",
    "adam = optimizers.Adam(clipnorm=max_norm)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "plot_model(model, to_file='model11.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 216228 samples, validate on 38158 samples\n",
      "Epoch 1/30\n",
      "216228/216228 [==============================] - 83s 383us/step - loss: 0.4585 - acc: 0.7836 - val_loss: 0.3387 - val_acc: 0.8489\n",
      "Epoch 2/30\n",
      "216228/216228 [==============================] - 77s 358us/step - loss: 0.3339 - acc: 0.8518 - val_loss: 0.2907 - val_acc: 0.8707\n",
      "Epoch 3/30\n",
      "216228/216228 [==============================] - 77s 358us/step - loss: 0.2840 - acc: 0.8762 - val_loss: 0.2540 - val_acc: 0.8901\n",
      "Epoch 4/30\n",
      "216228/216228 [==============================] - 79s 366us/step - loss: 0.2508 - acc: 0.8923 - val_loss: 0.2372 - val_acc: 0.9011\n",
      "Epoch 5/30\n",
      "216228/216228 [==============================] - 78s 362us/step - loss: 0.2264 - acc: 0.9040 - val_loss: 0.2215 - val_acc: 0.9059\n",
      "Epoch 6/30\n",
      "216228/216228 [==============================] - 77s 354us/step - loss: 0.2076 - acc: 0.9134 - val_loss: 0.2167 - val_acc: 0.9103\n",
      "Epoch 7/30\n",
      "216228/216228 [==============================] - 80s 368us/step - loss: 0.1914 - acc: 0.9195 - val_loss: 0.2166 - val_acc: 0.9120\n",
      "Epoch 8/30\n",
      "216228/216228 [==============================] - 77s 355us/step - loss: 0.1605 - acc: 0.9342 - val_loss: 0.2105 - val_acc: 0.9151\n",
      "Epoch 9/30\n",
      "216228/216228 [==============================] - 76s 350us/step - loss: 0.1503 - acc: 0.9387 - val_loss: 0.2111 - val_acc: 0.9166\n",
      "Epoch 10/30\n",
      "216228/216228 [==============================] - 76s 351us/step - loss: 0.1423 - acc: 0.9421 - val_loss: 0.2117 - val_acc: 0.9165\n",
      "Epoch 11/30\n",
      "216228/216228 [==============================] - 76s 352us/step - loss: 0.1413 - acc: 0.9427 - val_loss: 0.2116 - val_acc: 0.9167\n",
      "Epoch 12/30\n",
      "216228/216228 [==============================] - 76s 350us/step - loss: 0.1419 - acc: 0.9418 - val_loss: 0.2115 - val_acc: 0.9166\n"
     ]
    }
   ],
   "source": [
    "cp = ModelCheckpoint(filepath=\"my_model11.h5\", save_best_only=True)\n",
    "es = EarlyStopping(patience=4)\n",
    "rp = ReduceLROnPlateau(patience = 0)\n",
    "hist = model.fit([X1_train, X2_train], y_tra, batch_size = 256, epochs=30, validation_data=([X1_val, X2_val], y_val), callbacks=[cp, es, rp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check the loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': [0.33867928850287765, 0.29066097744481295, 0.2539949700829118, 0.23723506890782095, 0.22145563452128464, 0.21670218764988966, 0.21663831424535687, 0.21047602605301727, 0.21108358808362052, 0.2116915246489238, 0.21156324067795088, 0.2114531182748878], 'val_acc': [0.8489438649855655, 0.8706955291064095, 0.8901409927051306, 0.9011216520813252, 0.90594370774462, 0.9103464542198021, 0.9120236909722524, 0.9151423030588398, 0.9165836783929768, 0.9165050579202058, 0.916714712514262, 0.9165836783929768], 'loss': [0.4585069342285793, 0.33385557465469307, 0.28397650812175096, 0.2507942101699031, 0.22635987442274377, 0.2075881967404941, 0.19141293502141507, 0.16046838805848265, 0.15028927651565224, 0.1422973505443228, 0.14128396121112202, 0.14190482554849523], 'acc': [0.7836404166116295, 0.8518092013874975, 0.8762463695574215, 0.8923451171977288, 0.9040364800052236, 0.9134293430809537, 0.9195247608994283, 0.9341944614139824, 0.9386943411528937, 0.9421027804061867, 0.9426531253903313, 0.9417882975499131], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.000100000005, 0.000100000005, 1.0000001e-05, 1.0000001e-06, 1.0000001e-07]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1eb7c8c30f0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e9c6d0c8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print (hist.history)\n",
    "%matplotlib inline\n",
    "plt.figure(1)\n",
    "plt.plot (hist.history['loss'])\n",
    "plt.plot (hist.history['val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('my_model11.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict([X1_test, X2_test], batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make a submission file \n",
    "def make_submission(predict_prob):\n",
    "    with open('sub11.csv', 'w') as file:\n",
    "        file.write(str('y_pre') + '\\n')\n",
    "        for line in predict_prob:\n",
    "            #line = np.clip(line, 0.005, 0.995)\n",
    "            file.write(str(line[0]) + '\\n')\n",
    "    file.close()\n",
    "    \n",
    "make_submission(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
