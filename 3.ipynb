{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.8.0\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "from distutils.version import LooseVersion\n",
    "import warnings, os\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'  # 安装graphviz的路径，用于模型可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, SpatialDropout1D, GRU, BatchNormalization\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers import Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.models import Model, Sequential\n",
    "from keras import optimizers, layers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.utils import plot_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = 'chars' # based on words or chars\n",
    "embed_size = 300 # how big is each word vector\n",
    "max_features = 3048 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 58 # max number of words in a comment to use\n",
    "num_rnn_units = 64\n",
    "num_hidden_units = 200\n",
    "drop_prob = 0.2\n",
    "max_norm = 5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = './train.csv'\n",
    "TEST_PATH = './test.csv'\n",
    "QUESTION_PATH = './question.csv'\n",
    "embed_files = {'words': './word_embed.txt', 'chars': './char_embed.txt'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get question id from a list. Remove the Q\n",
    "def get_ids(qids):\n",
    "    ids = []\n",
    "    for t_ in qids:\n",
    "        ids.append(int(t_[1:]))\n",
    "    return np.asarray(ids)\n",
    "\n",
    "# Get the text\n",
    "def get_texts(q_list, question_path=QUESTION_PATH):\n",
    "    qes = pd.read_csv(question_path)\n",
    "    ids = get_ids(q_list)\n",
    "    all_tokens = qes[token]\n",
    "    texts = [all_tokens[t] for t in ids]\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train data\n",
    "split some data for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SJ\\AppData\\Local\\conda\\conda\\envs\\deep\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(TRAIN_PATH)\n",
    "list_train = list(zip(train['q1'], train['q2']))\n",
    "label_train = train['label']\n",
    "#print(len(list_train), len(label_train))\n",
    "\n",
    "X_tra, X_val, y_tra, y_val = train_test_split(list_train, label_train, train_size=0.85, random_state=8, shuffle=True)\n",
    "\n",
    "# get the text list of question 1 and 2\n",
    "q1_train = [i[0] for i in X_tra]\n",
    "text1_train = get_texts(q1_train)\n",
    "q2_train = [i[1] for i in X_tra]\n",
    "text2_train = get_texts(q2_train)\n",
    "q1_val = [i[0] for i in X_val]\n",
    "text1_val = get_texts(q1_val)\n",
    "q2_val = [i[1] for i in X_val]\n",
    "text2_val = get_texts(q2_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(TEST_PATH)\n",
    "list_test = list(zip(test['q1'], test['q2']))\n",
    "\n",
    "# get the text list of question 1 and 2\n",
    "q1_test = [i[0] for i in list_test]\n",
    "text1_test = get_texts(q1_test)\n",
    "q2_test = [i[1] for i in list_test]\n",
    "text2_test = get_texts(q2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_features, lower=False) # Don't lower the W or L!!!\n",
    "tokenizer.fit_on_texts(pd.read_csv(QUESTION_PATH)[token])\n",
    "\n",
    "# train set\n",
    "tokenized1_train = tokenizer.texts_to_sequences(text1_train)\n",
    "tokenized2_train = tokenizer.texts_to_sequences(text2_train)\n",
    "X1_train = pad_sequences(tokenized1_train, maxlen=maxlen)\n",
    "X2_train = pad_sequences(tokenized2_train, maxlen=maxlen)\n",
    "\n",
    "# validation set\n",
    "tokenized1_val = tokenizer.texts_to_sequences(text1_val)\n",
    "tokenized2_val = tokenizer.texts_to_sequences(text2_val)\n",
    "X1_val = pad_sequences(tokenized1_val, maxlen=maxlen)\n",
    "X2_val = pad_sequences(tokenized2_val, maxlen=maxlen)\n",
    "\n",
    "# test set\n",
    "tokenized1_test = tokenizer.texts_to_sequences(text1_test)\n",
    "tokenized2_test = tokenizer.texts_to_sequences(text2_test)\n",
    "X1_test = pad_sequences(tokenized1_test, maxlen=maxlen)\n",
    "X2_test = pad_sequences(tokenized2_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the pretrained word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3048\n"
     ]
    }
   ],
   "source": [
    "def get_coefs(line): return line[0], np.asarray(line[1:], dtype='float32')\n",
    "embed_file = embed_files[token]\n",
    "embeddings_index = dict(get_coefs(o.strip().split()) for o in open(embed_file, encoding='utf-8'))\n",
    "print (len(embeddings_index.items()))\n",
    "#print (list(embeddings_index.items())[20890])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.003230264, 2.2532277)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_embs = np.hstack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "emb_mean,emb_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (max_features+1, embed_size))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i > max_features: break\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    #print (i, word, len(embedding_vector))\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.asarray(embedding_matrix, dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 58)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 58)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       multiple             1101580     input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) [(None, 58, 128), (N 74112       sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 128)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 128)          0           bidirectional_2[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 384)          0           bidirectional_2[0][1]            \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "                                                                 bidirectional_2[1][1]            \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 384)          1536        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 200)          77000       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 200)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 200)          800         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 200)          40200       batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 200)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 200)          800         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 200)          40200       batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 200)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 200)          800         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 200)          40200       batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 200)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 200)          800         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            201         batch_normalization_5[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 1,378,229\n",
      "Trainable params: 461,161\n",
      "Non-trainable params: 917,068\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp1 = Input(shape=(maxlen,))\n",
    "inp2 = Input(shape=(maxlen,))\n",
    "\n",
    "# build the base model to share the weights between 2 questions\n",
    "base_model = Sequential()\n",
    "base_model.add(Embedding(max_features+1, embed_size, weights=[embedding_matrix], trainable = False, mask_zero=False))\n",
    "base_model.add(SpatialDropout1D(0.2))\n",
    "base_model.add(Bidirectional(LSTM(num_rnn_units, return_sequences=True, dropout=drop_prob, recurrent_dropout=drop_prob)))\n",
    "\n",
    "bigru = Bidirectional(GRU(num_rnn_units, return_sequences=True, return_state=True, dropout=drop_prob, recurrent_dropout=drop_prob))\n",
    "\n",
    "# q1\n",
    "outp1 = base_model(inp1)\n",
    "x1, h1, _ = bigru(outp1)\n",
    "gmp1 = GlobalMaxPooling1D()(x1)\n",
    "#gap1 = GlobalAveragePooling1D()(x1)\n",
    "\n",
    "#q2\n",
    "outp2 = base_model(inp2)\n",
    "x2, h2, _ = bigru(outp2)\n",
    "gmp2 = GlobalMaxPooling1D()(x2)\n",
    "#gap2 = GlobalAveragePooling1D()(x2)\n",
    "\n",
    "# Merge features from 2 questions\n",
    "conc = concatenate([h1, gmp1, h2, gmp2])\n",
    "x = BatchNormalization()(conc)\n",
    "x = Dense(num_hidden_units, activation=\"relu\")(x)\n",
    "x = Dropout(drop_prob)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(num_hidden_units, activation=\"relu\")(x)\n",
    "x = Dropout(drop_prob)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(num_hidden_units, activation=\"relu\")(x)\n",
    "x = Dropout(drop_prob)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(num_hidden_units, activation=\"relu\")(x)\n",
    "x = Dropout(drop_prob)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=[inp1, inp2], outputs=x)\n",
    "adam = optimizers.Adam(clipnorm=max_norm)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "model.summary()\n",
    "plot_model(model, to_file='model3.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 216228 samples, validate on 38158 samples\n",
      "Epoch 1/20\n",
      "216228/216228 [==============================] - 212s 983us/step - loss: 0.6132 - acc: 0.6770 - val_loss: 0.5410 - val_acc: 0.7451\n",
      "Epoch 2/20\n",
      "216228/216228 [==============================] - 205s 949us/step - loss: 0.4979 - acc: 0.7630 - val_loss: 0.4555 - val_acc: 0.7864\n",
      "Epoch 3/20\n",
      "216228/216228 [==============================] - 206s 953us/step - loss: 0.4480 - acc: 0.7875 - val_loss: 0.4111 - val_acc: 0.8077\n",
      "Epoch 4/20\n",
      "216228/216228 [==============================] - 206s 952us/step - loss: 0.4193 - acc: 0.8028 - val_loss: 0.3813 - val_acc: 0.8237\n",
      "Epoch 5/20\n",
      "216228/216228 [==============================] - 206s 954us/step - loss: 0.3933 - acc: 0.8165 - val_loss: 0.3609 - val_acc: 0.8354\n",
      "Epoch 6/20\n",
      "216228/216228 [==============================] - 205s 949us/step - loss: 0.3695 - acc: 0.8310 - val_loss: 0.3311 - val_acc: 0.8532\n",
      "Epoch 7/20\n",
      "216228/216228 [==============================] - 205s 949us/step - loss: 0.3461 - acc: 0.8433 - val_loss: 0.3162 - val_acc: 0.8604\n",
      "Epoch 8/20\n",
      "216228/216228 [==============================] - 205s 949us/step - loss: 0.3275 - acc: 0.8538 - val_loss: 0.2945 - val_acc: 0.8700\n",
      "Epoch 9/20\n",
      "216228/216228 [==============================] - 206s 955us/step - loss: 0.3133 - acc: 0.8613 - val_loss: 0.2851 - val_acc: 0.8781\n",
      "Epoch 10/20\n",
      "216228/216228 [==============================] - 206s 952us/step - loss: 0.3011 - acc: 0.8669 - val_loss: 0.2745 - val_acc: 0.8812\n",
      "Epoch 11/20\n",
      "216228/216228 [==============================] - 209s 968us/step - loss: 0.2912 - acc: 0.8716 - val_loss: 0.2736 - val_acc: 0.8828\n",
      "Epoch 12/20\n",
      "216228/216228 [==============================] - 207s 955us/step - loss: 0.2823 - acc: 0.8756 - val_loss: 0.2649 - val_acc: 0.8869\n",
      "Epoch 13/20\n",
      "216228/216228 [==============================] - 212s 980us/step - loss: 0.2762 - acc: 0.8790 - val_loss: 0.2586 - val_acc: 0.8886\n",
      "Epoch 14/20\n",
      "216228/216228 [==============================] - 208s 964us/step - loss: 0.2679 - acc: 0.8833 - val_loss: 0.2534 - val_acc: 0.8938\n",
      "Epoch 15/20\n",
      "216228/216228 [==============================] - 210s 971us/step - loss: 0.2636 - acc: 0.8846 - val_loss: 0.2564 - val_acc: 0.8902\n",
      "Epoch 16/20\n",
      "216228/216228 [==============================] - 222s 1ms/step - loss: 0.2517 - acc: 0.8910 - val_loss: 0.2469 - val_acc: 0.8964\n",
      "Epoch 17/20\n",
      "216228/216228 [==============================] - 206s 954us/step - loss: 0.2472 - acc: 0.8933 - val_loss: 0.2450 - val_acc: 0.8974\n",
      "Epoch 18/20\n",
      "216228/216228 [==============================] - 204s 946us/step - loss: 0.2460 - acc: 0.8935 - val_loss: 0.2445 - val_acc: 0.8981\n",
      "Epoch 19/20\n",
      "216228/216228 [==============================] - 227s 1ms/step - loss: 0.2445 - acc: 0.8931 - val_loss: 0.2433 - val_acc: 0.8993\n",
      "Epoch 20/20\n",
      "216228/216228 [==============================] - 206s 951us/step - loss: 0.2419 - acc: 0.8954 - val_loss: 0.2429 - val_acc: 0.8986\n"
     ]
    }
   ],
   "source": [
    "cp = ModelCheckpoint(filepath=\"my_model3.h5\", save_best_only=True)\n",
    "es = EarlyStopping(patience=2)\n",
    "rp = ReduceLROnPlateau(patience = 0)\n",
    "hist = model.fit([X1_train, X2_train], y_tra, batch_size = 512, epochs=20, validation_data=([X1_val, X2_val], y_val), callbacks=[cp, es, rp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check the loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': [0.5409890103217684, 0.4555462426631679, 0.41106459560887393, 0.38125913075614987, 0.3608577945280627, 0.3310879673686778, 0.31619122213890943, 0.2945081370607525, 0.2850524290839271, 0.27450434610281194, 0.2735653380217608, 0.26492538454616477, 0.25861774302421175, 0.2534075517113075, 0.25635990262550157, 0.24693393119007945, 0.24503068160827046, 0.24446677734244637, 0.2433265074177654, 0.2429080333944774], 'val_acc': [0.7450862206330032, 0.7863881754371579, 0.8077205302261807, 0.823654279502547, 0.8353687298767122, 0.8531631638221605, 0.8604224540726295, 0.8699617382396511, 0.8780596466507825, 0.8811782589435603, 0.882776875017049, 0.886865139738607, 0.8886209968169959, 0.8937837412643622, 0.8901934064192507, 0.8964044239056286, 0.8973740764031389, 0.8980816606580789, 0.8992871742208797, 0.8986057967901967], 'loss': [0.6132462077901444, 0.49793065772975814, 0.44796145895573297, 0.41932374304243347, 0.39328133167771445, 0.36953499947341906, 0.3460613537842958, 0.32751032830316723, 0.3132855962666753, 0.30108331587304593, 0.29121024317529864, 0.2823081093206102, 0.27620755952645293, 0.2678560616013777, 0.2635709715800957, 0.25168463586051854, 0.24717707977616535, 0.24603434828193202, 0.2444982048087757, 0.24191782015858554], 'acc': [0.677002978336578, 0.7630417892268979, 0.7874512089179354, 0.8028146216053279, 0.8164853765668254, 0.83097471189805, 0.8433366631452425, 0.8537885935326793, 0.8612945594443049, 0.8668627559952359, 0.8715753741211594, 0.8756127790825889, 0.8789610966047975, 0.8832667369518092, 0.884570915865237, 0.8910039402742282, 0.8933486874855052, 0.8934874299284528, 0.8930665778560692, 0.8954020755990094], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.000100000005, 0.000100000005, 0.000100000005, 0.000100000005, 0.000100000005]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x240a26bf208>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xl8VPW5+PHPM5OVJARIwhb2EHaQJbKL1hVEwQUtaq1Wva7U2t7bW/21t/Vie6+3vbZai7u9Vavirohad1BElqDsWxJACGsSCCRkT57fH2eC05hlILMkM8/79ZrXzDnne855chiec+Z7vuf7FVXFGGNMZHCFOgBjjDHBY0nfGGMiiCV9Y4yJIJb0jTEmgljSN8aYCGJJ3xhjIoglfWOMiSCW9I0xJoJY0jfGmAgSFeoAGkpNTdV+/fqFOgxjjGlX1qxZU6iqaS2Va3NJv1+/fmRnZ4c6DGOMaVdE5Btfyln1jjHGRBBL+sYYE0Es6RtjTASxpG+MMRHEkr4xxkQQS/rGGBNBLOkbY0wECZukX1xWxUMf5bBx79FQh2KMMW1Wm3s461S5XMJDH2+ntq6OEenJoQ7HGGPapLC50u8YF82oXp34Iq8o1KEYY0ybFTZJH2DKwBTW7SmmtLIm1KEYY0ybFFZJf3JGKjV1yqqddrVvjDGN8Snpi8h0EdkmIrkicncTZa4Ukc0isklEXvCaf52I5Hhe1/kr8MaM69uZmCgXy3Mt6RtjTGNavJErIm5gAXAekA+sFpFFqrrZq0wmcA8wRVWPiEhXz/wuwG+ALECBNZ51j/j/T4G4aDdZfTtbvb4xxjTBlyv98UCuqu5Q1SpgITC7QZl/ARbUJ3NVPeSZfwHwoaoe9iz7EJjun9AbN2VgKlv2H6OotDKQuzHGmHbJl6SfDuzxms73zPM2CBgkIl+IyAoRmX4S6yIiN4tItohkFxQU+B59IyZnpADw5Q672jfGmIZ8SfrSyDxtMB0FZAJnAVcBT4lIJx/XRVWfUNUsVc1KS2tx4JdmjUxPJik2ii+sXt8YY77Dl6SfD/T2mu4F7GukzFuqWq2qO4FtOCcBX9b1qyi3iwkDurA8rzCQuzHGmHbJl6S/GsgUkf4iEgPMBRY1KPMm8D0AEUnFqe7ZAbwPnC8inUWkM3C+Z15ATc5I5ZuiMvKPlAV6V8YY0660mPRVtQaYh5OstwAvq+omEZkvIrM8xd4HikRkM/Ap8HNVLVLVw8B9OCeO1cB8z7yAmjIwFYDl1orHGGP+iah+p4o9pLKysrS1A6OrKqf/7iOmDkzlwblj/BSZMca0XSKyRlWzWioXVk/k1hMRJmWk8kVeEW3tpGaMMaEUlkkfYEpGCgUlleQeKg11KMYY02aEb9K3en1jjPmOsE36vbt0oHeXeL7ItaabxhhTL2yTPsCUjFRW7Ciits7q9Y0xBsI86U/KSOFYRY0NoWiMMR5hnfQnZzj1+l/Y07nGGAOEedJPS4plcLckvrSbucYYA4R50geYPDCF1bsOU1lTG+pQjDEm5MI+6U/JSKWiuo6vvikOdSjGGBNyYZ/0xw/ogkuwXjeNMYYISPod46IZ1auTtdc3xhgiIOkDTBmYwrr8o5RUVIc6FGOMCanISPoZqdTWKat3BbxXZ2OMadMiIumP7duZmCiXDaFojIl4EZH046LdZPXtbPX6xpiIFxFJH5xeN7ceKKGwtDLUoRhjTMj4lPRFZLqIbBORXBG5u5Hl14tIgYis9bxu8lpW6zW/4di6QTM5IwXAns41xkS0qJYKiIgbWACcB+QDq0VkkapublD0JVWd18gmylV1dOtDbZ2R6ckkxUaxPK+Ii0/rGepwjDEmJHy50h8P5KrqDlWtAhYCswMblv9FuV1MGJBiD2kZYyKaL0k/HdjjNZ3vmdfQ5SKyXkReFZHeXvPjRCRbRFaIyCWtCba1Jmek8E1RGflHykIZhjHGhIwvSV8amddwVJK3gX6qOgr4CHjGa1kfzwjtVwMPikjGd3YgcrPnxJBdUFDgY+gn78QQitZ00xgToXxJ+vmA95V7L2CfdwFVLVLV+mYxTwLjvJbt87zvAJYAYxruQFWfUNUsVc1KS0s7qT/gZAzqlkhqYqz1r2+MiVi+JP3VQKaI9BeRGGAu8E+tcESkh9fkLGCLZ35nEYn1fE4FpgANbwAHjYgwOSOF5XlFqNoQisaYyNNi0lfVGmAe8D5OMn9ZVTeJyHwRmeUpdqeIbBKRdcCdwPWe+UOBbM/8T4H7G2n14z/lxVDVfH39lIEpFJRUknuoNGBhGGNMW9Vik00AVX0XeLfBvF97fb4HuKeR9ZYDI1sZo28O74AFE2DmAzD2h00WOzGEYm4hmd2SghKaMca0FeHzRG7n/pDcGza80myx3l060LtLPF/YQ1rGmAgUPklfBEZeATs/h2P7my06JSOVFTuKqKmtC1JwxhjTNoRP0gcn6aOw6fVmi00emEpJRQ0b9x0LTlzGGNNGhFfSTx0IPcfA+pebLTZpgNMPjz2da4yJNOGV9MG52t+/FgpzmiySlhTL4G5J9pCWMSbihF/SH34ZILDh1WaLTR6Ywupdh6morg1OXMYY0waEX9Lv2AP6n+G04mnmAawpGalU1tTx1e4jQQzOGGNCK/ySPjhVPIfzYN/XTRaZMKALbpdYFY8xJqKEZ9IfOgvcMc1W8STFRTOqV7LdzDXGRJTwTPrxnSDzfNj4GtQ1XWc/OSOFdflHKamoDmJwxhgTOuGZ9MGp4ik9ALs+b7LIlIxUauuUVTsPBzEwY4wJnfBN+oMugJikZrtlGNu3M7FRLr6wen1jTIQI36QfHQ9DL4bNb0N1RaNF4qLdZPXrbPX6xpiIEb5JH2DkHKg8CrkfNllkckYqWw+UUFha2WQZY4wJF+Gd9PufCQlpzXbLMDnD6ZLhS+t10xgTAcI76bujYMTlsP19qDjaaJGR6ckkxUZZFY8xJiKEd9IHpxVPbSVsWdzo4ii3iwkDUuxmrjEmIoR/0k8fB537NduKZ8rAFHYfLmPP4eaHWjTGmPbOp6QvItNFZJuI5IrI3Y0sv15ECkRkred1k9ey60Qkx/O6zp/B++TE4CpLoeRgo0WmDHSGULQqHmNMuGsx6YuIG1gAzACGAVeJyLBGir6kqqM9r6c863YBfgNMAMYDvxGRzn6L3lcjrwCtg01vNLo4s2siqYmxLLebucaYMOfLlf54IFdVd6hqFbAQmO3j9i8APlTVw6p6BPgQmH5qobZC2mDoPhI2NN6KR0SYnJHC8rwitJmeOY0xpr3zJemnA3u8pvM98xq6XETWi8irItL7JNcNvJFXwt41UJTX6OIpA1MoKKkk51BpkAMzxpjg8SXpSyPzGl4Ovw30U9VRwEfAMyexLiJys4hki0h2QUGBDyGdghGXO+FsfK3RxZMznHr9xev2BWb/xhjTBviS9POB3l7TvYB/yoyqWqSq9Y+0PgmM83Vdz/pPqGqWqmalpaX5GvvJSU6HvlOcB7UaqcLp3aUDF47szuOf7bBWPMaYsOVL0l8NZIpIfxGJAeYCi7wLiEgPr8lZwBbP5/eB80Wks+cG7vmeeaExcg4U5cCB9Y0u/tXMYbhEmL94c5ADM8aY4Ggx6atqDTAPJ1lvAV5W1U0iMl9EZnmK3Skim0RkHXAncL1n3cPAfTgnjtXAfM+80Bg2G1zRTXbL0LNTPHeek8mHmw/yydbGm3caY0x7Jm2ttUpWVpZmZ2cHbgcvXuUMo/jTTeByf2dxVU0dMx76jOpa5YOfTiMu+rtljDGmrRGRNaqa1VK58H8it6GRc6BkP3yzvNHFMVEu5s8ewe7DZTy2tPGWPsYY015FXtIfNAOiE1roliGVi0b14JEleewuspu6xpjwEXlJP6YDDL0INr8FNU33of+rmcOIcgn/+famIAZnjDGBFXlJH5xuGSqKIffjJot0T47jrnMz+XjrIT7abDd1jTHhITKT/oCzoENKk90y1PvRlP5kdk3k3rc3UVFdG5TQjDEmkCIz6bujYfhlsO09qCxpsli027mpm3+knEeW2E1dY0z7F5lJH5wqnpoK2PpOs8UmZaQwe3RPHluax67C40EKzhhjAiNyk37v8dCpT7OteOr9vwuHEuN2ce/bm6wXTmNMuxa5SV8ERsyBvE+htPlO3rp1dG7qLtlWwAd2U9cY045FbtIHz+AqtbD5zRaLXje5H4O7JTH/7c2UV9lNXWNM+xTZSb/bMOg6vMm+eLw5N3WHs7e4nAWf5gYhOGOM8b/ITvoAo66A/FVweGeLRScMSOGyMek88dkOdhTYYCvGmPbHkv6Iy533JgZXaejuC4cQG+XiN4vspq4xpv2xpN+pD/SZ5LTi8SGJd02K42fnD+LznEL+sfFAEAI0xhj/saQPTs+bBVvhoG/97Fw7sS9Duicxf/FmyqpqAhycMcb4jyV9gGGXgiuqxW4Z6kW5Xdx3yQj2H63g4U/spq4xpv2wpA+QkAIZZ8OG16CuzqdVTu/XhcvH9uKpz3eQe8hu6hpj2gefkr6ITBeRbSKSKyJ3N1NujoioiGR5pvuJSLmIrPW8HvNX4H438ko4lg+7Gx9cpTH3XDiEuGg399pNXWNMO9Fi0hcRN7AAmAEMA64SkWGNlEvCGR93ZYNFeao62vO61Q8xB8bgGRDfBT74D6j1rZ4+NTGWn18wmGW5hby7wW7qGmPaPl+u9McDuaq6Q1WrgIXA7EbK3Qf8HqjwY3zBE5sIMx+AfV/BFw/6vNo1E/oyvGdH7lu8mdJKu6lrjGnbfEn66cAer+l8z7wTRGQM0FtVFzeyfn8R+VpElorIGaceahCMuAyGXwpL7ocDG3xaxe0S5s8ewYFjFTz8cU6AAzTGmNbxJelLI/NOVGCLiAv4E/CvjZTbD/RR1THAz4AXRKTjd3YgcrOIZItIdkFB852fBdyFD0B8J3jjNqip8mmVcX07c2VWL55etpMt+48FOEBjjDl1viT9fKC313QvYJ/XdBIwAlgiIruAicAiEclS1UpVLQJQ1TVAHjCo4Q5U9QlVzVLVrLS0tFP7S/wlIQUufggOboDP/uDzar+YPoROHaK59ulVbD1gid8Y0zb5kvRXA5ki0l9EYoC5wKL6hap6VFVTVbWfqvYDVgCzVDVbRNI8N4IRkQFAJrDD73+Fvw2ZCaPmwucPwN6vfFolJTGWhTdPxO2CuU+sYH1+cYCDNMaYk9di0lfVGmAe8D6wBXhZVTeJyHwRmdXC6tOA9SKyDngVuFVVD7c26KCYcT8kdoM3b4Nq3+5ND+yaxCu3TCYxNoqrn1zJqp3t4081xkQOaWvty7OysjQ7OzvUYThyPoLnL4cpP4Hz5vu82v6j5Vzz1Er2FZfzxLVZTBsU4iorY0zYE5E1qprVUjl7Irc5mefC2Otg+cOwu+HjB03rkRzPy7dMon9qIjc9k837m6wNvzGmbbCk35ILfgcdeznVPFVlPq+WmhjLwn+ZyLCeHbn9+a94a+3eAAZpjDG+saTfktgkuGQBHM6Dj//zpFZN7hDN32+awOn9OnPXS2t5cdXuAAVpjDG+saTvi/7TYPwtsPIx2Pn5Sa2aGBvF3340njMHpXHP6xt4elnLI3QZY0ygWNL31bm/gS4D4K3bobLkpFaNi3bzxLVZzBjRnfsWb+bhj3OsgzZjTEhY0vdVTAJc8igU73E6ZTvZ1aNcPHzVGC4bm84DH27n/n9stcRvjAm6qFAH0K70mQiT5zmteYZeBAPPPanVo9wu/nfOaXSIcfP40h2UVdbyn7OG43I11tOFMcb4n13pn6zv/QpSB8NbP4byk3/q1uUS7ps9glumDeC5Fd/w81fXU1Pr28AtxhjTWpb0T1Z0HFz6KJQehH/cc0qbEBHunjGEn503iNe+yufOhV9TVWOJ3xgTeJb0T0X6ODjjZ7DuBdj67iltQkS485xMfjVzKO9uOMAtz2VTUV3r50CNMeafWdI/VdP+HbqNhLd/AmWn3sfOTWcM4L8uHcmS7QX86P9W20AsxpiAsqR/qqJinGqe8iPw7r+1alNXT+jDn64czapdh/n+419y8Fj7HHzMGNP2WdJvje4j4cxfwMbXYNMbrdrUJWPSeeqHWewsPM6lC76wPvmNMQFhSb+1pv4Ueo6BxT+D0kOt2tT3hnTl5VsmUavKFY9+yec5IR5FzBgTdizpt5Y7Ci55DKqOw+KfQisfuBqRnsybd0whvXM8P/q/1by02vrrMcb4jyV9f+g6BM7+FWxdDKuebPXmeiTH88qtk5g8MJVfvLaBP7y/lbo6e3rXGNN6lvT9ZdIdMGgGvPdzWP1UqzeXFBfN09dlcdX43iz4NI+7XlpLZY016TTGtI4lfX9xueHKZ5zE/86/+uWKP9rt4r8uHckvpg9h0bp9XPvUKo4cr/JDsMaYSOVT0heR6SKyTURyReTuZsrNEREVkSyvefd41tsmIhf4I+g2KyoWrnwWBs90mnGueKzVmxQRbjsrg4evGsPa/GIue3Q5uwqP+yFYY0wkajHpi4gbWADMAIYBV4nIsEbKJQF3Aiu95g0D5gLDgenAI57tha+oGLjibzDkIvjHL+DLR/yy2YtP68kLN02guKyKyx5dzppvbNB1Y8zJ8+VKfzyQq6o7VLUKWAjMbqTcfcDvAe8ni2YDC1W1UlV3Arme7YW3+sQ/dBa8fw8s/4tfNpvVrwuv3z6FjnFRXPXkSt5Zv98v2zXGRA5fkn46sMdrOt8z7wQRGQP0VtXFJ7tu2HJHw5y/wrBL4INfwhcP+WWz/VMTeP32KYxKT+aOF77isaV51i+/McZnviT9xjp7P5FlRMQF/An415Nd12sbN4tItohkFxSE0QNJ7mi4/GkYfhl8+GtY9ie/bLZLQgx/v2kCF5/Wk/vf28ov39xo3TMbY3ziyyAq+UBvr+lewD6v6SRgBLBERAC6A4tEZJYP6wKgqk8ATwBkZWWF12WrOwouexLEBR/dC3W1MK11ffWAMwTjQ98fTe/O8TyyJI+9R8pZcM1YEmNtXBxjTNN8udJfDWSKSH8RicG5MbuofqGqHlXVVFXtp6r9gBXALFXN9pSbKyKxItIfyARW+f2vaOvcUXDp4zDySvjkPlj6B79s1uUS/n36EP77spEsyy1kzqPL2Vdc7pdtG2PCU4tJX1VrgHnA+8AW4GVV3SQi8z1X882tuwl4GdgM/AO4Q1Uj8wkjdxRc+hiMmguf/haW3O+3TV81vg9/vf508o+Uc/HDy/gyr8hv2zbGhBdpazcBs7KyNDs7O9RhBE5dLSz6Max93umh86x7QPwzRm7uoRJueW4Nu4rKuGfGEG6c2h/x07aNMW2biKxR1ayWytkTucHmcsOsv8CYH8DS/4FPf9fqTtrqDeyaxJt3TOHcoV357TtbuHPhWsqqbFAWY8y37K5fKLhccPHDzs3dz/4AWgdn/4dfrviT4qJ57AfjeGRJHv/7wTa2Hyjh8WvH0S81wQ+BG2PaO7vSDxWXCy56CMZdD58/4LTs8dMVv4hwx/cG8syPxnOwpIKL/7KMT7Ye9Mu2jTHtmyX9UHK5YOafIOsG+OJBpy2/H++xTBuUxtvzptKnSwdu+Fs2D3603bpoNibCWdIPNZcLZv4RTr8Jlv8ZXrupVQOtN9S7Swdeu20yl41N58GPcviXZ7M5Wl7tt+0bY9oXS/ptgQhc+L/wvV/B5jfhkUmw/QO/bT4u2s0DV5zGfbOHs3R7AbP+sszG4DUmQlnSbytE4Myfw00fQ4cu8MIV8NY8qPBPchYRrp3Uj4U3T6S8qpZLFyxn0brvPBxtjAlzlvTbmp6j4eYlzoDra5+HRyfDjqV+23xWvy4s/vFUhvfsyJ0vfs1vF2+2fnuMiSCW9NuiqFg491644QPn87Oz4N2fO4Ov+0HXjnG88C8TuX5yP55atpMfPL2SwtJKv2zbGNO2WdJvy3qfDrd8DhNug1VPwGNTYffKltfzQUyUi3tnDeePV57G17uLufjhZXy9+4hftm2Mabss6bd1MR1gxv1w3WKoq4G/XgAf/AdUV7S8rg8uG9uL126bjNslfP/xFbywcrf1z29MGLOk3170PwNuW+48zLX8z/DEmbD3K79sekR6Mm/Pm8rEjBT+3xsb+PdX11NRHZn94hkT7izptyexSXDxg3DNa06rnqfOhU//C2qqWr3pzgkx/N/1p3PnOZm8siafyx9dzp7DZX4I2hjTlljSb48yz4Xbv4RRVzqdtj11Nhzc1OrNul3Cz84bxNPXZbHncBkXPbyMT7cd8kPAxpi2wpJ+exXfyemff+4LUHIAHj/T6cOntvW9ap4ztBtv/3gqPTvFc8PfVlv3DcaEEUv67d2QmXD7ShhyIXw8H16+1i/VPX1TEnj9tslcOsbpvuHGZ1ZTXNb67RpjQsuSfjhISIErnoHp/wPb3vUk/ta3u4+Pcbpv+O0lI1iWW8hFDy9j496jfgjYGBMqlvTDhQhMvBVmPgDb/wEv/cAvzTpFhB9M7MvLt0yitk65/NHlvJy9xw8BG2NCwaekLyLTRWSbiOSKyN2NLL9VRDaIyFoRWSYiwzzz+4lIuWf+WhF5zN9/gGng9Jvgogch5wN46Rq/tecf06czi388lXF9O/Pvr67nntc3UFljzTqNaW9aTPoi4gYWADOAYcBV9UndywuqOlJVRwO/B/7otSxPVUd7Xrf6K3DTjKwfwcV/htyPYOFVUF3ul82mJMby7A3jue2sDF5ctZsrH/uSvcX+2bYxJjh8udIfD+Sq6g5VrQIWArO9C6iqd1eQCYA19Qi1cdc5Y/HmfQovzoUq/7S5j3K7+MX0ITx+7Th2FBznoj9/zrKcQr9s2xgTeL4k/XTAuxI33zPvn4jIHSKSh3Olf6fXov4i8rWILBWRMxrbgYjcLCLZIpJdUFBwEuGbZo29Fi55xOml88Xv+63DNoALhnfnrXlTSEuK5Yd/XcmCT3OtWacx7YAvSb+x0bq/879bVReoagbwC+BXntn7gT6qOgb4GfCCiHRsZN0nVDVLVbPS0tJ8j960bPTVTnv+XcvgBf8m/gFpibx5xxQuGtWTP7y/jZufW8PRMhuVy5i2zJeknw/09pruBTQ3+sZC4BIAVa1U1SLP5zVAHjDo1EI1p+y0uXDpE/DNF/D8FVBZ6rdNd4iJ4qG5o7n34mEs2XaIc/64lLfW7rVO24xpo3xJ+quBTBHpLyIxwFxgkXcBEcn0mpwJ5Hjmp3luBCMiA4BMYIc/AjcnadQVcNmTsHsFPD8HKkv8tmkR4fop/Xnzjimkd4rjJwvXcu3Tq9hZ6L9fFcYY/2gx6atqDTAPeB/YArysqptEZL6IzPIUmycim0RkLU41znWe+dOA9SKyDngVuFVV/Tfqtzk5I+fA5U/BnlXw98v9NhRjvRHpybx++xTumz2cdXuKueDBz3jwo+3WY6cxbYi0tZ/hWVlZmp2dHeowwtumN+G1G6HnGPjBaxCX7PddHCqp4HfvbOGttfvol9KB+y4ZwRmZdr/GmEARkTWqmtVSOXsiNxINvwSu+Bvs+xqeuxTKi/2+i65JcTw0dwx/v3GCMyj706u488WvOVTin4fFjDGnxpJ+pBp6MVz5LOxfD89dAuWBGSpxamYq7/3kDO46N5N/bDzAOQ8s5dkvd1FrzTuNCQlL+pFsyEz4/nNOX/zPXgJlgbndEhft5q5zB/GPu87gtF6d+PVbm7j0kS+s8zZjQsCSfqQbPAO+/zwc2gzPzobSwA2aMiAtkeduHM9Dc0ezr7iCWX9Zxr2LNlFSYW37jQkWS/oGBp0Pc1+Egm3w0Gj48NdwPDBdK4gIs0en8/G/nsk1E/ryzJe7OOeBpbyzfr+17TcmCKz1jvlWwTZn+MWNr0N0PJx+I0y+ExK7BmyXa/cU88s3NrBp3zGmDUrj1xcNZWDXpIDtz5hw5WvrHUv65rsKtsFn/wsbXwV3LGTdAFN+AkndArK7mto6nlvxDQ98sJ3jVTWcP6wbt581kNN6dwrI/owJR5b0TesV5jjJf8PL4I6BcT9ykn/HHgHZXVFpJX9bvou/Ld9FSUUNUwemcvtZGUzKSEGksS6gjDH1LOkb/ynKcwZdX7cQXFEw7nqYehd07BmQ3ZVUVPP8yt08vWwnBSWVnNa7E7eflcF5Q7vhclnyN6YxlvSN/x3eAZ//Eda9COKCsT+EqT+F5F4B2V1FdS2vrsnn8c/y2HO4nMyuidx6ZgazRvck2m1tEIzxZknfBM6RXU7yX/s8IE6//VN/Cp36BGR3NbV1vLNhP48uyWPrgRLSO8Vz87QBXJnVm/gYd0D2aUx7Y0nfBF7xblj2J/jqOWd69NVw1t0Bq/ZRVT7ZeohHluSx5psjpCTEcMPU/vxgYl+S46MDsk9j2gtL+iZ4juZ7kv+zEJPgDNM49KKA7U5VWbXzMI8syWPp9gKSYqO4ZmJfbpzan7Sk2IDt15i2zJK+Cb7CXKf3zv1rnZY+F/wXxHQI6C437j3Ko0vzeHfDfqLdLi4dnc41E/swqpc19zSRxZK+CY2aKvjkPlj+Z0gbApc/Dd1HBHy3OwuP88RnO3jz672UV9cyIr0j10zoy6zTepIQGxXw/RsTapb0TWjlfQJv3Op023zefJhwCwShrf2ximre+novf1+xm20HS0iMjeLSMelcPaEPQ3t8Z3hmY8KGJX0TescL4a07YPs/IPMCuOQRSEgNyq5Vla92H+H5FbtZvGE/VTV1jO3TiWsm9GXmqB7ERVurHxNe/Jr0RWQ68BDgBp5S1fsbLL8VuAOoBUqBm1V1s2fZPcCNnmV3qur7ze3Lkn6YUYVVT8IHv4L4TnDJozDwnKCGcOR4Fa99lc8LK3ezo/A4yfHRzBnXi6vG92Fg18SgxmJMoPgt6XsGNt8OnAfk4wyUflV9UveU6aiqxzyfZwG3q+p0ERkGvAiMB3oCHwGDVLXJQVMt6YepAxudm7wFW2HSPDjnNxAVE9QQVJUvdxTx/MrdfLDpANW1ysQBXbhmQl8uGN6dmCh74Mu0X74mfV/ucI0HclV1h2fDC4HZwImkX5/wPRKA+jPJbGChqlYCO0Uk17O9L336K0z46D4Cbl7iXPF/+RdkctyUAAAR2UlEQVTY9blzkzc1M2ghiAiTM1KZnJFKQUklr6zZwwsrd/PjF78mNTGGOeN6M2dcL7v6N2HNl6SfDuzxms4HJjQsJCJ3AD8DYoCzvdZd0WDd9FOK1LR/0fEw8wHIONup6398Gsz4PYz5QVBu8npLS4rl9rMGcuu0DD7LKeCFlbt54rM8Hluax6BuicwY0YMLR/ZgULdE6+zNhBVfkn5j3/jv1Amp6gJggYhcDfwKuM7XdUXkZuBmgD59AvMov2lDhsyEnmPgjVtg0TzI+xguetCp8w8yl0s4a3BXzhrclYPHKnhvw37e3XiAP3+Sw0Mf55CRlsCFI3swY0QPhvZIshOAafd8qdOfBNyrqhd4pu8BUNX/bqK8CziiqskNy4rI+55tNVm9Y3X6EaSu1mnP/8lvIakHXPYk9J0U6qgAOFRSwfubDvLehv2s2FFEnUK/lA7MGNmDC0f0YER6RzsBmDbFnzdyo3Bu5J4D7MW5kXu1qm7yKpOpqjmezxcDv1HVLBEZDrzAtzdyPwYy7Uau+Sd718CrN0LxNzD8Uhh6MQw8F2LbxghaRaWVfLD5IO9tPMDy3EJq6pReneM9vwC6M7p3JzsBmJDzd5PNC4EHcZps/lVVfyci84FsVV0kIg8B5wLVwBFgXv1JQUR+CdwA1AB3qep7ze3Lkn6Eqixxrvg3vAplhc6IXQPOcqqCBs8I6JCNJ6O4rIoPPSeAz3MKqK5VeibHMX1EDy4c2Z2xfTpbn/8mJOzhLNM+1dXCnpWwZTFsfdvpyROBPhOdE8CQi6BL/1BHCcDR8mo+2XqQdzccYOn2Aqpq6khNjOGswV05Z0hXpmamkhRnvX+a4LCkb9o/VTi4Eba+A1sXw4ENzvyuw51ePIfMhO6jgt7ypzGllTV8svUQH285yJJtBRwtrybaLYzv34Wzh3TjnCFd6ZeaEOowTRizpG/Cz5FdsPVd5wSw+0vQOkju4/kFMBP6TAJ36DtXq6mt46vdxXyy9RCfbD3I9oOlAAxITeDsIV05e2hXTu/XxUb/Mn5lSd+Et+OFTp8+WxY7nbvVVkJ8F+cXwMgroO8UcLWN/nX2HC7znAAO8WVeEVW1dSTFRjFtUBpnD+nKWYPTSEm0cQBM61jSN5GjstRJ/Fvehm3vQlWp0wR0+GUwco7zTEAbqAICOF5Zwxe5hSdOAodKKhGB0b07cc6QrkzKSGFYj2QbBtKcNEv6JjJVlTm/ADa+BjkfQG0VdMlwrv5Hzglqtw8tqatTNu8/xsdbnGqgdflHAXC7hMyuiYxMT2ZUr2RG9urEkO5J1jOoaZYlfWPKjzhX/xtegZ2fAwo9TnNOAMMvg+S21SNIQUkla/cUsyG/mPV7j7Ih/yhFx6sAiHIJg7snMapXMiPSkxmV3onB3ZOskzhzgiV9Y7wd2w+b3nBOAPu+AsSp9x85B4bNhg5dQh3hd6gq+45WsCH/KBv2FrM+/ygb9h6luKwagBi3iyE9kr79RZDeiUHdEomyG8QRyZK+MU0pynMeAtvwChTlgCvaeQJ45BzoPhKiYiEq7tt3dyy42kYiVVXyj5SzPv8o6/cWe04IRympqAEgKS6KKRmpTBuUxrRBqfTqHNgxik3bYUnfmJaowoH1TvLf8BqU7Gu6rDvmn08EUbHOyaDhCSJtMGSeD73Hgzs4D2bV1Sm7D5exLr+YL/OK+Gx7AfuOVgAwIC2BaZlpnDk4jYn9U+wGcRizpG/Myairg/xVcGwv1FRCTcXJv1eVQeE2qKuB2I6Q8T0YeB5kngdJ3YP2p6gquYdKWbq9gM9yClm5o4jKmjpiolyM79eFaYOcXwKDu1mvoeHEkr4xoVBxDHYscVoO5X4EJfud+d1HOck/83xIzwrqQ2QV1bWs2nmYz7YX8FlOwYmHxbp1jOWMzDSmDUrjjIGpdE4I7khmxr8s6RsTavXdSOR86Lz2rASthbhkyDjHOQkMPDfoncntP1rO59sLWZpTwLKcQo6WVyMCo9KTGdOnM31TOtAvNYF+KQn06hxvTw63E5b0jWlryothx6eQ8xHkfgilB535PUY7vwAyz4OeY4P6K6C2TlmfX8zS7QV8nlPI1v3HOF71bc/nbpfQq3M8/VIS6Fd/MrATQptkSd+YtqyuDg5ucKqBcj5y7idoHUR3cE4C6WM9r3HQqW/QnihWVQpLq9hVdJxdhced96Iy53Ph8WZPCH1TEhjfvwsj0pODEqv5Z5b0jWlPyg47vwL2rIK9X8H+dU5/QuD0KZQ+zvMa6/waSEwLeoj1J4Rvio6zs/A43xSVsbPoON8UHWdXYRmllU6z0RHpHZl7eh9mj+5pXUsHkSV9Y9qz2mo4uMl5kGzvGtj7NRRscX4NgNO7aP0vgfSxzq+D2MSQhauqFJRW8t6GA7y4ajdbD5QQH+3molE9mDu+D2P72OhigWZJ35hwU1nq/AI4cSJY4xlkBhAXpA52upnoOhS6DoNuw6BjetA7m1NV1uUfZeGq3Sxat4+yqloGdUtk7ul9uGxsOp06WCuhQLCkb0wkOF7oVAfVnwgObPznh8xiO357Eug6zPncbXjru52oq3X2XXoASjyv0kPO8wiDZ0BCKuAMLvP2un0sXLWbdflHiYlyceGI7swd34cJ/bvY1b8f+XuM3OnAQzhj5D6lqvc3WP4z4CaccXALgBtU9RvPslrAM+QRu1V1VnP7sqRvTCuVH4FDW+HQJji0xXkd3AQVxd+WSezmORkM9zopDHGePC49CCUHGyT0A17zDsLxQ99WNTUkLug98dvBbTzDW27ed4yFq3fzxtd7KamoYUBqAt8/vTeXj+tFqo0n0Gp+S/oi4ga2A+cB+cBq4CpV3exV5nvASlUtE5HbgLNU9fueZaWq6nNloyV9YwJA1UneDU8EBdugpryFlQUS0iCpGyR293r3vOrnJXSFwu3fDm95cKOzercR354Auo+ivLqOdzbsZ+Gq3WR/c4Rot3DesG7MPb0PUwem2sDyp8ifSX8ScK+qXuCZvgdAVf+7ifJjgL+o6hTPtCV9Y9qqulpnGMpDm50TgdY5vwKSunveezgJ/1SeHTi80xnUZus7TQ5vmVNYzsLVe3j9q3yOlFUTH+2mX2oCA1ITGJCWQP9U5zUgLZHkeGsJ1Bx/Jv05wHRVvckzfS0wQVXnNVH+L8ABVf2tZ7oGWItT9XO/qr7Z3P4s6RsTho4Xwrb3nBPAieEtO8OgGTBkJpX9zuTDnBK+3l3MzsLj7CgoZc+Rcmrrvs1PKQkxnhNAAv1TE+mfmkBGWgJ9UjoQG2Udyfma9H05fTf2W6vRM4WI/ADIAs70mt1HVfeJyADgExHZoKp5Dda7GbgZoE+fPj6EZIxpVxJSYey1zqt+eMuti2HbO7DuBWKj4rlo4Dlc1HMMdOsEcZ2ojk7iQFUcu8ui2VHiZluxi+2Ha/hkawGFpfknNu0SSO8cz4DURLomxRIf4yYu2nnFR7uJj3Y5n2O+nXdiWYyrQVl32Fcv+a16R0TOBR4GzlTVQ01s62/AYlV9tan92ZW+MRGkthq++cJzH+Adp5fT5rhjIS6Z2rhkKtyJlJLAkboOFFTHsb8yhuLqKMrrXFTUuiivdVGDm2qiqMVFtbqpIcozz02t571G3SfKVREF0fFITAJRsfFExXYgNiaOxLhoEmKjSIiNIjHWTWJsNAmxbhJPzHPek+OjSUmMoXOHGNxBPnn4s3onCudG7jnAXpwbuVer6iavMmOAV3GqgXK85ncGylS1UkRSgS+B2d43gRuypG9MBKuugIqjTkujiqNeL6/p8obLvMrU1fg9pFpcVBJLBTGUE0uZxlCmMVQQQ4U68yqIplxjqSKKOlzU4iY6OpqYmGhiomOIi40hLiaG+NgY4mJj6RAXQ4e4GBLiYkmIjyU2OhpxRzv3TzLPO6U4/Va9o6o1IjIPeB+nyeZfVXWTiMwHslV1EfAHIBF4xdPutr5p5lDgcRGpA1w4dfpNJnxjTISLjnNeSd1Ofl1VJ+nX1Ti/IE6813+ucT6fmFf77ef6ZTWVUF3utGiqLofqMtzVFXSoLqdDddmJZXVVZc6rsgytLkGry3FVl0FdldOvUl0NorW4KmtxV9ZCqW9/ws64YfS/+9SSvq98uiWvqu8C7zaY92uvz+c2sd5yYGRrAjTGGJ+IOKOVuaMhOj6gu3J5Xj6rqwOtpbKqkiOlFRwuKePI8QqKS8ooPl5B8fFyjh6voHNiB24LUMz1gteHqzHGRCqXc5qIjY+me3wi3YPfX963oYRu18YYY4LNkr4xxkQQS/rGGBNBLOkbY0wEsaRvjDERxJK+McZEEEv6xhgTQSzpG2NMBGlzwyWKSAHwTSs2kQoU+imcQLD4Wsfiax2Lr3Xacnx9VbXFx77aXNJvLRHJ9qXToVCx+FrH4msdi6912np8vrDqHWOMiSCW9I0xJoKEY9J/ItQBtMDiax2Lr3UsvtZp6/G1KOzq9I0xxjQtHK/0jTHGNKFdJn0RmS4i20QkV0TubmR5rIi85Fm+UkT6BTG23iLyqYhsEZFNIvKTRsqcJSJHRWSt5/XrxrYV4Dh3icgGz/6/Mz6lOP7sOYbrRWRsEGMb7HVs1orIMRG5q0GZoB5DEfmriBwSkY1e87qIyIcikuN579zEutd5yuSIyHVBjO8PIrLV8+/3hoh0amLdZr8LAYzvXhHZ6/VveGET6zb7/z2A8b3kFdsuEVnbxLoBP35+part6oUzZGMeMACIAdYBwxqUuR14zPN5LvBSEOPrAYz1fE7CGV+4YXxn4QwQH8rjuAtIbWb5hcB7gAATgZUh/Pc+gNMGOWTHEJgGjAU2es37PXC35/PdwP80sl4XYIfnvbPnc+cgxXc+EOX5/D+NxefLdyGA8d0L/JsP//7N/n8PVHwNlj8A/DpUx8+fr/Z4pT8eyFXVHapaBSwEZjcoMxt4xvP5VeAc8QzeG2iqul9Vv/J8LgG2AOnB2LefzQaeVccKoJOI9AhBHOcAearamgf2Wk1VPwMON5jt/T17BrikkVUvAD5U1cOqegT4EJgejPhU9QNVrR8pfAXQy9/79VUTx88Xvvx/b7Xm4vPkjiuBF/2931Boj0k/HdjjNZ3Pd5PqiTKeL/1RICUo0XnxVCuNAVY2sniSiKwTkfdEZHhQA3Mo8IGIrBGRmxtZ7stxDoa5NP2fLdTHsJuq7gfnZA90baRMWzmON+D8cmtMS9+FQJrnqX76axPVY23h+J0BHFTVnCaWh/L4nbT2mPQbu2Jv2ATJlzIBJSKJwGvAXap6rMHir3CqK04DHgbeDGZsHlNUdSwwA7hDRKY1WN4WjmEMMAt4pZHFbeEY+qItHMdfAjXA800Uaem7ECiPAhnAaGA/ThVKQyE/fsBVNH+VH6rjd0raY9LPB3p7TfcC9jVVRkSigGRO7aflKRGRaJyE/7yqvt5wuaoeU9VSz+d3gWgRSQ1WfJ797vO8HwLewPkZ7c2X4xxoM4CvVPVgwwVt4RgCB+urvDzvhxopE9Lj6LlxfBFwjXoqoBvy4bsQEKp6UFVrVbUOeLKJ/Yb6+EUBlwEvNVUmVMfvVLXHpL8ayBSR/p4rwbnAogZlFgH1rSTmAJ809YX3N0/939PAFlX9YxNlutffYxCR8Tj/DkXBiM+zzwQRSar/jHPDb2ODYouAH3pa8UwEjtZXZQRRk1dYoT6GHt7fs+uAtxop8z5wvoh09lRfnO+ZF3AiMh34BTBLVcuaKOPLdyFQ8XnfI7q0if368v89kM4FtqpqfmMLQ3n8Tlmo7ySfygunZcl2nLv6v/TMm4/z5QaIw6kSyAVWAQOCGNtUnJ+f64G1nteFwK3ArZ4y84BNOC0RVgCTg3z8Bnj2vc4TR/0x9I5RgAWeY7wByApyjB1wkniy17yQHUOck89+oBrn6vNGnPtEHwM5nvcunrJZwFNe697g+S7mAj8KYny5OPXh9d/D+hZtPYF3m/suBCm+5zzfrfU4ibxHw/g809/5/x6M+Dzz/1b/nfMqG/Tj58+XPZFrjDERpD1W7xhjjDlFlvSNMSaCWNI3xpgIYknfGGMiiCV9Y4yJIJb0jTEmgljSN8aYCGJJ3xhjIsj/B7vh3TffxsxkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24096b84a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print (hist.history)\n",
    "%matplotlib inline\n",
    "plt.figure(1)\n",
    "plt.plot (hist.history['loss'])\n",
    "plt.plot (hist.history['val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('my_model3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict([X1_test, X2_test], batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make a submission file \n",
    "def make_submission(predict_prob):\n",
    "    with open('sub3.csv', 'w') as file:\n",
    "        file.write(str('y_pre') + '\\n')\n",
    "        for line in predict_prob:\n",
    "            #line = np.clip(line, 0.005, 0.995)\n",
    "            file.write(str(line[0]) + '\\n')\n",
    "    file.close()\n",
    "    \n",
    "make_submission(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
